---
layout: homepage
---

## About Me 

I am social psychologist with a strong engineering background. Prior to joining the University of Southern California, 
I completed a  BS and MS in Process Engineering at the Berlin Institute of Technology. 
Originally, I was interested in using machine learning for control systems and process optimization, 
but I became increasingly interested in using these methods to model human behavior instead. 
I then completed a BS in psychology at Free University Berlin, and transitioned to
studying complex human interactions through a combination of computational and behavioral methods. 
Currently, my research focuses on grounding computational methods in psychological theory to advance our knowledge of various social phenomena. 

## Research Interests 

- **Morality, Values, and Pro-social Behavior:** How do humans conceptualize moral values and how do they guide our behavior, good or bad?
- **Online & Social Media Behavior:** What insights does online behavior across various contexts provide about hate, conflicts, as well as mental health & well-being? 
- **Theory-Driven Computational Models:** How can we place top-down, theory-driven constraints on computational methods to increase interpretability and robustness? 

## Research Methods 
- **Machine Learning:** Applying machine learning to explore untapped information sources and facilitate novel insights about social phenomena.
- **Natural Language Processing:** Applying NLP to extract psychological information from textual data. Critically examine what language models can tell us about human psychology. 
- **Agent-based Models:** Simulating large-scale social interactions to elucidate the underlying dynamics of moral behaviors and use these insights to facilitate pro-social behavior. 
- **Bayesian Multilevel Models:** Applying advaced modeling techniques to generate more robust and generalizable research findings. 


<!-- ## News -->
<!--  -->
<!-- - **[Aug. 2023]** Coming soon. -->


{% include_relative _includes/publications.md %} 

## Conferences 
- Abdurahman, S., Reimer, N. K., Golazizian, P., Baek, E., Shen, Y., Trager, J., Lulla, R., Kaplan, J., Parkinson, C., Dehghani, M. (2024). Investigating the Impact of Targeting Audiences' Moral Values on Sharing Online-Misinformation. SPSP
- Abdurahman, S., Vu, H., Zou, W., Ungar, L., Bhatia, S. (2024). A Deep Language Approach to Personality Assessment: Generalizing Across Items and Expanding the Reach of Survey-Based Research. SPSP
- Abdurahman, S., Vu, H. (2023). Investigating Social Inferences in Large Language Models: Advancements and Biases. Psychology of Technology
- Abdurahman, S., Preston, E. (2023). Sharing is in Fact about Caring: Care Concerns Feature Prominently on Subreddits Devoted to Self-Injurious Thoughts and Behaviors. SPSP
- Abdurahman, S., Osborne, M., Trager, J., Omrani, A., Dehghani, M. (2022). Fighting Fire with Fire: How groups incentivize incivility on social media platforms. Psychology of Technology
- Abdurahman, S., Osborne, M., Omrani, A. (2022). Responding to Wrongdoing: Status Conferral in Online Conflicts. Media \& Technology Preconference @ SPSP

## Papers in preparation & under review 
- **Targeting Audiences' Moral Values Shapes Misinformation Sharing:** We analyze how  moral framing can increase dissemination of online misinformation and its potential for
targeted misinformation campaigns. We combine large-scale social media analyses with rigorous behavioral experiments and find that matched moral framing in line with individuals'
or groups' moral values increases its spread independent of message veracity, familiarity or believability. 
- **Perils and Opportunities in Using Large Language Models in Psychological Research**: 
Not only are Large Language Models (LLMs) such as ChatGPT becoming increasingly embedded in people's everyday life in many societies, they are becoming an important tool in psychological research. 
Here, we highlight the risks associated with the rushed application of these technologies to psychological research, a practice we call ``GPTology.''   
We review and conduct a comprehensive analysis of both the benefits and risks associated with using LLMs in psychological research and 
advocate for the development of reliable applications and the use of open, interpretable models. We also quantify, and warn against, cultural biases of LLMs. 
A more inclusive approach is critical to ensuring reproducible, generalizable, and unbiased scientific insights, when employing LLMs to study the human mind. 
- **Contextual Moral Values and Categorization:** We propose a framework that emphasizes the role of representations and categorization in understanding moral values and their underlying neural processes. 
In this framework, individuals hold distinct notions of right and wrong, with real-life scenarios contextually mapping onto these representations as exemplars (e.g., via perception of prototypicality) or through associated features (e.g., perceived harm). 
Through multiple empirical studies, we investigate the intricate interplay between context, moral judgments, and value representations in the brain, offering theory-informed insights into vital moral topics. 
By embracing context and a representation lens, we enhance the scope of moral psychology research, deepening our grasp of context-sensitive moral judgments, and facilitating the integration of diverse moral theories. 
- **Social inferences in language models:** We investigate how fine-tuned smaller encoder-based language models (e.g., BERT) and large generative language models (GPT-3, GPT-4) interpret social cues and psychometrics 
from responses to diverse psychological surveys, including non-traditional questionnaire formats. We evaluate these models' abilities against human raters, focusing on accuracy and bias, 
particularly concerning demographic representations. Our findings reveal that both model types demonstrate a high capacity for making accurate social inferences, 
with large language models like ChatGPT showing superior performance even in zero-shot scenarios. However, LLMs also exhibit more pronounced biases and present interpretability challenges 
compared to their smaller counterparts which allow access to the model's underlying representations of the social cues. We suggest that reducing LLM biases requires advanced prompting techniques and 
targeted fine-tuning, which can further enhance their inference accuracy. Our comparison highlights the nuanced trade-offs between model accuracy, bias, and transparency in the context of social inference tasks.
- **Counter-normative status conferral on social media platform:** We combine large-scale social media analysis with behavioral experiments to investigate how and when groups punish or reward norm-violations. 
Specifically, we analyze whether groups reward social-norm violations, such as incivility and aggression, when attacked by outgroup members and contrast this to their reaction during non-aggressive outgroup interaction. 
We find that groups punish norm-violations when perceiving the outgroup as non-aggressive and reward it when feeling attacked. Our results underline past work on tit-for-tat cycles of incivility 
as well as group dynamics rewarding commitment to and defense of the group, elucidating the quick deterioration of online discourse and the rapid spread of toxicity. 

## Past Projects 

- **Master's Thesis:** _Joschka Schulz & Matthias Kraume (TU Berlin)_ <br> 
An exemplary study on automated categorisation and evaluation of peer-reviewed scientific literature concerning interfacial effects in disperse multi-phase systems 

- **Bachelor's Thesis:** _Philipp Schäpers & Stefan Krumm (FU Berlin)_ <br> 
Predicting Job-Ratings from Job-Postings using Natural Language Processing: A Machine Learning Approach to Understanding Corporate Language 

- **Bachelor's Thesis:** _Lia Strenge & Jörg Raisch (TU Berlin)_ <br> 
Model Identification for Designing a PWM-based Solar Charge Controller 

{% include_relative _includes/services.md %}

## Contact 
Address: 3620 McClintock Ave, Los Angeles CA 90089\
Office Location: SGM 604\
Email: sabdurah@usc.edu\
<!-- Phone: (XXX) XXX-XXXX --> 


