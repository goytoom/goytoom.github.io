---
layout: homepage
---

## About Me 
I am social psychologist with a strong engineering background. Prior to joining the University of Southern California, 
I completed a  BS and MS in Process Engineering at the Berlin Institute of Technology. 
Originally, I was interested in using machine learning for control systems and process optimization, 
but I became increasingly interested in using these methods to model human behavior instead. 
I then completed a BS in psychology at Free University Berlin, and transitioned to
studying complex human interactions through a combination of computational and behavioral methods. 
Currently, my research focuses on grounding computational methods in psychological theory to advance our knowledge of various social phenomena. 

## Research Interests 

- **Psychology of AI:**: How can studying the psychology of AI systems improve AI functionality and interaction (e.g., human-centered AI), and potentially even deepen our understanding of human psychology?
- **Morality, Values, and Pro-social Behavior:** How do humans conceptualize moral values and how do they guide our behavior, good or bad?
- **Online & Social Media Behavior:** What insights does online behavior across various contexts provide about hate, conflicts, as well as mental health & well-being? 
- **Theory-Driven Computational Models:** How can we place top-down, theory-driven constraints on computational methods to increase interpretability and robustness? 

## Research Methods 
- **Machine Learning:** Applying machine learning to explore untapped information sources and facilitate novel insights about social phenomena.
- **Natural Language Processing:** Applying NLP to extract psychological information from textual data. Critically examine what language models can tell us about human psychology. 
- **Agent-based Models:** Simulating large-scale social interactions to elucidate the underlying dynamics of moral behaviors and use these insights to facilitate pro-social behavior. 
- **Bayesian Multilevel Models:** Applying advaced modeling techniques to generate more robust and generalizable research findings. 


<!-- ## News -->
<!--  -->
<!-- - **[October. 2024]** Coming soon. -->


{% include_relative _includes/publications.md %} 

## Conferences 
- Abdurahman, S., Reimer, N. K., Golazizian, P., Baek, E., Shen, Y., Trager, J., Lulla, R., Kaplan, J., Parkinson, C., Dehghani, M. (2024). Investigating the Impact of Targeting Audiences' Moral Values on Sharing Online-Misinformation. SPSP
- Abdurahman, S., Vu, H., Zou, W., Ungar, L., Bhatia, S. (2024). A Deep Language Approach to Personality Assessment: Generalizing Across Items and Expanding the Reach of Survey-Based Research. SPSP
- Abdurahman, S., Vu, H. (2023). Investigating Social Inferences in Large Language Models: Advancements and Biases. Psychology of Technology
- Abdurahman, S., Preston, E. (2023). Sharing is in Fact about Caring: Care Concerns Feature Prominently on Subreddits Devoted to Self-Injurious Thoughts and Behaviors. SPSP
- Abdurahman, S., Osborne, M., Trager, J., Omrani, A., Dehghani, M. (2022). Fighting Fire with Fire: How groups incentivize incivility on social media platforms. Psychology of Technology
- Abdurahman, S., Osborne, M., Omrani, A. (2022). Responding to Wrongdoing: Status Conferral in Online Conflicts. Media \& Technology Preconference @ SPSP

## Current Projects 
- **Targeting Audiences' Moral Values Shapes Misinformation Sharing:** We analyze how moral framing increases dissemination of online misinformation and its potential for
targeted misinformation campaigns. We combine large-scale social media analyses with behavioral experiments and find that matched moral framing in line with individuals'
 moral values increases its spread independent of message veracity, familiarity or believability. 
 - **Evaluating Large Language Models in Psychological Research: A Guide for Authors and Reviewers:** We provide a set of best practices for authors and reviewers in psychological research
  involving Large Language Models (LLMs). Our guide emphasizes methodological rigor, replicability, and transparency, addressing the challenges posed by the non-deterministic nature of LLMs. 
  By ensuring robust and valid applications of LLMs, we aim to support high-quality, innovative research in the evolving landscape of psychological studies
- **Explaining Explainability: Interpretable machine learning for the behavioral sciences:** We advocate for the adoption of interpretable Machine Learning (ML) techniques in behavioral sciences,
 dispelling misconceptions that ML models are 'black boxes' and unsuitable for inference. By highlighting the nuanced nature of model interpretability, 
 the compatibility of interpretability with predictive accuracy, and the potential of post hoc explanations, we encourage the use of ML models to both predict and understand complex behavioral phenomena.
- **Contextual Moral Values and Categorization:** We propose a novel framework that emphasizes the role of representations and categorization for moral values.
In this framework, individuals hold distinct notions of right and wrong, with real-life scenarios contextually mapping onto these representations as exemplars (e.g., via perception of prototypicality) or through associated features (e.g., perceived harm). 
Through multiple empirical studies, we investigate the interplay between context, moral judgments, and value representations in the brain, offering theory-informed insights into vital moral topics. 
By embracing context and a representation lens, we enhance the scope of context-sensitive moral psychology research and facilitate the integration of diverse moral theories. 
- **Social inferences in language models:** We investigate the social inferences from responses to psychological questionnaires in small fine-tuned encoder-based language models (e.g., BERT) and large generative language models (GPT-3.5, GPT-4)
Our comparison with human raters reveals that generative models stand out in accuracy but show more biases and are less transparent than smaller models. 
We further find that addressing biases in LLMs benefits from few-shot prompting and targeted fine-tuning, underscoring the trade-offs between accuracy, bias, and transparency in applying language models to social inference tasks.
- **Counter-normative status conferral on social media platform:** We combine large-scale social media analysis with behavioral experiments to investigate how and when groups punish or reward norm-violations, such as aggression and incivility. 
We find that groups punish norm-violations when perceiving the outgroup as non-aggressive and reward it when feeling attacked. Our results underline past work on tit-for-tat cycles of incivility 
and show that group dynamics, which  reward commitment to and defense of the group, contribute to the quick deterioration of online discourse and the rapid spread of toxicity. 

## Past Projects 

- **Master's Thesis:** Advised by  _Morteza Dehghani_ (University of Southern California)_ <br>
How Misinformation Exploits Moral Values and Framing: Insights from Social Media Platforms and Behavioral Experiments

- **Master's Thesis:** Advised by _Joschka Schulz & Matthias Kraume (TU Berlin)_ <br> 
An exemplary study on automated categorisation and evaluation of peer-reviewed scientific literature concerning interfacial effects in disperse multi-phase systems 

- **Bachelor's Thesis:** Advised by _Philipp Schäpers & Stefan Krumm (FU Berlin)_ <br> 
Predicting Job-Ratings from Job-Postings using Natural Language Processing: A Machine Learning Approach to Understanding Corporate Language 

- **Bachelor's Thesis:** Advised by _Lia Strenge & Jörg Raisch (TU Berlin)_ <br> 
Model Identification for Designing a PWM-based Solar Charge Controller 

{% include_relative _includes/services.md %}

## Contact 
Address: 3620 McClintock Ave, Los Angeles CA 90089\
Office Location: SGM 604\
Email: sabdurah@usc.edu\
<!-- Phone: (XXX) XXX-XXXX --> 


